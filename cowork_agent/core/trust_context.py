"""
Trust Context — Content origin and trust level tracking.

Every message and tool result gets tagged with where it came from and how
much the agent should trust it. This is the foundation for content isolation:
user messages are TRUSTED, tool results are SEMI_TRUSTED, and web content
is UNTRUSTED.

Sprint 23: Anthropic-grade security.
"""

from __future__ import annotations

import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Optional


class ContentOrigin(Enum):
    """Where content comes from."""
    USER_CHAT = "user_chat"           # Direct user message in conversation
    TOOL_RESULT = "tool_result"       # Output from tool execution
    WEB_CONTENT = "web_content"       # From web_fetch / web_search
    FILE_CONTENT = "file_content"     # From read tool / file system
    SYSTEM = "system"                 # Generated by agent internals


class TrustLevel(Enum):
    """Trustworthiness of the source."""
    TRUSTED = "trusted"               # User messages — highest trust
    SEMI_TRUSTED = "semi_trusted"     # Tool results, file content
    UNTRUSTED = "untrusted"           # Web content, external APIs

    def __lt__(self, other: TrustLevel) -> bool:
        order = {TrustLevel.UNTRUSTED: 0, TrustLevel.SEMI_TRUSTED: 1, TrustLevel.TRUSTED: 2}
        return order[self] < order[other]

    def __le__(self, other: TrustLevel) -> bool:
        return self == other or self < other


# ── Tools that produce untrusted content ────────────────────────

UNTRUSTED_TOOLS = frozenset({
    "web_fetch",
    "web_search",
})

# ── Tools that produce semi-trusted content ─────────────────────

SEMI_TRUSTED_TOOLS = frozenset({
    "read",
    "glob",
    "grep",
    "bash",
    "edit",
    "write",
    "notebook_edit",
    "todo_write",
    "ask_user",
    "task",
})


@dataclass
class TrustContext:
    """Metadata tracking source and trustworthiness of content.

    Attached to every Message and ToolResult so the security pipeline
    can make trust-aware decisions (e.g., scanning untrusted outputs
    more aggressively for prompt injection).
    """
    origin: ContentOrigin
    trust_level: TrustLevel
    source_tool: Optional[str] = None   # Which tool generated it
    source_url: Optional[str] = None    # If from web content
    timestamp: float = field(default_factory=time.time)

    # ── Factory methods ──────────────────────────────────────────

    @staticmethod
    def for_user_message() -> TrustContext:
        """Create trust context for a direct user message (highest trust)."""
        return TrustContext(
            origin=ContentOrigin.USER_CHAT,
            trust_level=TrustLevel.TRUSTED,
        )

    @staticmethod
    def for_tool_result(tool_name: str) -> TrustContext:
        """Create trust context for a tool execution result.

        web_fetch and web_search → UNTRUSTED
        All other tools          → SEMI_TRUSTED
        """
        if tool_name in UNTRUSTED_TOOLS:
            return TrustContext(
                origin=ContentOrigin.WEB_CONTENT,
                trust_level=TrustLevel.UNTRUSTED,
                source_tool=tool_name,
            )
        return TrustContext(
            origin=ContentOrigin.TOOL_RESULT,
            trust_level=TrustLevel.SEMI_TRUSTED,
            source_tool=tool_name,
        )

    @staticmethod
    def for_file_content(tool_name: str = "read") -> TrustContext:
        """Create trust context for file content."""
        return TrustContext(
            origin=ContentOrigin.FILE_CONTENT,
            trust_level=TrustLevel.SEMI_TRUSTED,
            source_tool=tool_name,
        )

    @staticmethod
    def for_system() -> TrustContext:
        """Create trust context for system-generated content."""
        return TrustContext(
            origin=ContentOrigin.SYSTEM,
            trust_level=TrustLevel.TRUSTED,
        )

    # ── Helpers ──────────────────────────────────────────────────

    @property
    def is_trusted(self) -> bool:
        return self.trust_level == TrustLevel.TRUSTED

    @property
    def is_untrusted(self) -> bool:
        return self.trust_level == TrustLevel.UNTRUSTED

    def to_dict(self) -> dict:
        return {
            "origin": self.origin.value,
            "trust_level": self.trust_level.value,
            "source_tool": self.source_tool,
            "source_url": self.source_url,
            "timestamp": self.timestamp,
        }

    def __repr__(self) -> str:
        tool = f", tool={self.source_tool}" if self.source_tool else ""
        return f"TrustContext({self.origin.value}, {self.trust_level.value}{tool})"
